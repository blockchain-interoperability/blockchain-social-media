{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from collections import Counter\n",
    "from itertools import chain,combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af9dc1bd49ee408496cfa7e69cc41331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loading tokens...:   0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ce27b36a62641a5827938af06e2bb37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://towardsdatascience.com/topic-modeling-with-bert-779f7db187e6\n",
    "\n",
    "from collect_data import load_cache\n",
    "from tokenizer import load_tokens\n",
    "\n",
    "tokens = load_tokens('/data/blockchain-interoperability/blockchain-social-media/analysis/twitter/tokens/text')\n",
    "data = load_cache('/data/blockchain-interoperability/blockchain-social-media/analysis/twitter/snapshots')\n",
    "\n",
    "data['clean_text'] = [' '.join(t) for t in tokens]\n",
    "data.sort_values('timestamp_ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sample = pd.read_pickle('snapshots/00100000.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    Never seen such a deal for a punk since 2017! ...\n",
       "2    Collection: ens \\n Sold for: 1.0040189 Eth (12...\n",
       "Name: whole_text, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.whole_text[[1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f41a1b2a13dd43e89048255156703459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loading embeddings..:   0%|          | 0/221 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from embeddings import load_embeddings\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "import torch\n",
    "# ee = load_embeddings()\n",
    "\n",
    "ee = [\n",
    "    torch.load(f) \n",
    "    for f in tqdm(\n",
    "        sorted(\n",
    "            Path('embeddings/all-MiniLM-L6-v2/').glob('*.pkl')\n",
    "        ),\n",
    "        desc='loading embeddings..',\n",
    "        leave=False\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f3944c2e06f416493978246264b30ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "reading in snapshots..:   0%|          | 0/221 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dataset import TwitterDataset\n",
    "dset = TwitterDataset(\n",
    "    'snapshots',\n",
    "    'tokens/text/',\n",
    "    'embeddings/all-MiniLM-L6-v2/',\n",
    "    'sentiment/vader/'\n",
    "    '2022-11-09 06:00:00.000000'\n",
    "    '2022-11-10 06:00:00.000000'    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "       \n",
    "        #Encoder\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(16, 4, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "        )\n",
    "        # nn.MaxPool2d(2, 2)\n",
    "       \n",
    "        #Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(4, 16, 2, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(16, 3, 2, stride=2),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearAutoEncoder, self).__init__()\n",
    "       \n",
    "        #Encoder\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(384, 200),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.MaxPool2d(2,2),\n",
    "            nn.Linear(200,50),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.MaxPool2d(2,2),\n",
    "        )\n",
    "        # nn.MaxPool2d(2, 2)\n",
    "       \n",
    "        #Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(50, 200),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(200,384),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a805b4a530094a9b8cb5054e3c1b5cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.002409222535789013\n",
      "loss: 0.004125208128243685\n",
      "loss: 0.0023909281007945538\n",
      "loss: 0.002432329813018441\n",
      "loss: 0.002463673474267125\n",
      "loss: 0.0024721170775592327\n",
      "loss: 0.0024827364832162857\n",
      "loss: 0.0024854594375938177\n",
      "loss: 0.00248575652949512\n",
      "loss: 0.0024866077583283186\n",
      "loss: 0.002486886689439416\n",
      "loss: 0.0024863595608621836\n",
      "loss: 0.0024846415035426617\n",
      "loss: 0.002483841497451067\n",
      "loss: 0.002484808675944805\n",
      "loss: 0.002484197961166501\n",
      "loss: 0.0024825020227581263\n",
      "loss: 0.002481407020241022\n",
      "loss: 0.002481244271621108\n",
      "loss: 0.0024815055076032877\n",
      "loss: 0.002481007482856512\n",
      "loss: 0.0024796975776553154\n",
      "loss: 0.002478713868185878\n",
      "loss: 0.0024784798733890057\n",
      "loss: 0.0024782337713986635\n",
      "loss: 0.002477183472365141\n",
      "loss: 0.0024760758969932795\n",
      "loss: 0.002475673332810402\n",
      "loss: 0.0024754612240940332\n",
      "loss: 0.002474902430549264\n",
      "loss: 0.0024742414243519306\n",
      "loss: 0.0024734698235988617\n",
      "loss: 0.002472821855917573\n",
      "loss: 0.0024727489799261093\n",
      "loss: 0.0024716167245060205\n",
      "loss: 0.002471020445227623\n",
      "loss: 0.002470472827553749\n",
      "loss: 0.002470012754201889\n",
      "loss: 0.0024696404580026865\n",
      "loss: 0.002469132887199521\n",
      "loss: 0.002468761056661606\n",
      "loss: 0.0024684052914381027\n",
      "loss: 0.0024678038898855448\n",
      "loss: 0.0024671631399542093\n",
      "loss: 0.002466714708134532\n",
      "loss: 0.0024663074873387814\n",
      "loss: 0.0024658124893903732\n",
      "loss: 0.002465310972183943\n",
      "loss: 0.0024648611433804035\n",
      "loss: 0.00246432819403708\n",
      "loss: 0.0024637572932988405\n",
      "loss: 0.002463269978761673\n",
      "loss: 0.0024628022219985723\n",
      "loss: 0.002462257631123066\n",
      "loss: 0.0024617277085781097\n",
      "loss: 0.0024612434208393097\n",
      "loss: 0.002460752846673131\n",
      "loss: 0.0024603393394500017\n",
      "loss: 0.002459994750097394\n",
      "loss: 0.0024595463182777166\n",
      "loss: 0.0024590203538537025\n",
      "loss: 0.00245852954685688\n",
      "loss: 0.0024580666795372963\n",
      "loss: 0.002457601949572563\n",
      "loss: 0.0024572014808654785\n",
      "loss: 0.002456807531416416\n",
      "loss: 0.0024563733022660017\n",
      "loss: 0.0024559753946959972\n",
      "loss: 0.002455526264384389\n",
      "loss: 0.0024550564121454954\n",
      "loss: 0.0024546273052692413\n",
      "loss: 0.0024541805032640696\n",
      "loss: 0.002453769790008664\n",
      "loss: 0.0024533551186323166\n",
      "loss: 0.0024529460351914167\n",
      "loss: 0.0024525283370167017\n",
      "loss: 0.0024520112201571465\n",
      "loss: 0.0024517232086509466\n",
      "loss: 0.0024511879310011864\n",
      "loss: 0.002450884785503149\n",
      "loss: 0.0024504566099494696\n",
      "loss: 0.0024499755818396807\n",
      "loss: 0.0024494556710124016\n",
      "loss: 0.002448765328153968\n",
      "loss: 0.0024484312161803246\n",
      "loss: 0.0024480707943439484\n",
      "loss: 0.002447524107992649\n",
      "loss: 0.0024473080411553383\n",
      "loss: 0.0024469569325447083\n",
      "loss: 0.0024465343449264765\n",
      "loss: 0.002446037484332919\n",
      "loss: 0.00244556344114244\n",
      "loss: 0.0024450842756778\n",
      "loss: 0.002444571815431118\n",
      "loss: 0.0024443399161100388\n",
      "loss: 0.0024436975363641977\n",
      "loss: 0.002443452598527074\n",
      "loss: 0.002443156437948346\n",
      "loss: 0.002442784607410431\n",
      "loss: 0.0024423464201390743\n"
     ]
    }
   ],
   "source": [
    "lenc = lenc.cuda()\n",
    "ebs = ebs.cuda()\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from torch.optim import Adam\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = Adam(lenc.parameters())\n",
    "\n",
    "for epoch in tqdm(range(100)):\n",
    "    optimizer.zero_grad()\n",
    "    out = lenc(ebs)\n",
    "    loss = criterion(out,ebs)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print('loss:',loss.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 ('blockchain-sns-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "6cd29d4fa90de0455862d632ba5d82eded8ec761054fa1c425c75462c69e58ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
