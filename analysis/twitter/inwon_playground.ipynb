{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from collections import Counter\n",
    "from itertools import chain,combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af9dc1bd49ee408496cfa7e69cc41331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loading tokens...:   0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ce27b36a62641a5827938af06e2bb37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://towardsdatascience.com/topic-modeling-with-bert-779f7db187e6\n",
    "\n",
    "from collect_data import load_cache\n",
    "from tokenizer import load_tokens\n",
    "\n",
    "tokens = load_tokens('/data/blockchain-interoperability/blockchain-social-media/analysis/twitter/tokens/text')\n",
    "data = load_cache('/data/blockchain-interoperability/blockchain-social-media/analysis/twitter/snapshots')\n",
    "\n",
    "data['clean_text'] = [' '.join(t) for t in tokens]\n",
    "data.sort_values('timestamp_ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "tokens = pickle.load(open('tokens/text/00100000.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "000ef5f2d4c34afd9a58518ffb8bdfb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "minibatch..:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from embeddings import get_sbert_embedding\n",
    "\n",
    "ebs = get_sbert_embedding(tokens,'all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "       \n",
    "        #Encoder\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(16, 4, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "        )\n",
    "        # nn.MaxPool2d(2, 2)\n",
    "       \n",
    "        #Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(4, 16, 2, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(16, 3, 2, stride=2),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearAutoEncoder, self).__init__()\n",
    "       \n",
    "        #Encoder\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(384, 200),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.MaxPool2d(2,2),\n",
    "            nn.Linear(200,50),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.MaxPool2d(2,2),\n",
    "        )\n",
    "        # nn.MaxPool2d(2, 2)\n",
    "       \n",
    "        #Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(50, 200),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(200,384),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def _flatten(self, h, batch_size):\n",
    "    # (num_layers*num_directions, batch_size, hidden_dim)  ==>\n",
    "    # (batch_size, num_directions*num_layers, hidden_dim)  ==>\n",
    "    # (batch_size, num_directions*num_layers*hidden_dim)\n",
    "    return h.transpose(0,1).contiguous().view(batch_size, -1)\n",
    "\n",
    "\n",
    "class LSTMEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTMEncoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            384,\n",
    "            50,\n",
    "            num_layers = 2,\n",
    "            bidirectional = True,\n",
    "            dropout=.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        # math: num_layer * num_directions, batch_size, hidden_dim\n",
    "        self.hidden = (torch.zeros(2 * 2, 100000, 50).cuda(),\n",
    "                        torch.zeros(2 * 2, 100000, 50).cuda())\n",
    "    def forward(self,x):\n",
    "        batch_size = x.size(0)\n",
    "        _,self.hidden = self.lstm(x,self.hidden)\n",
    "        x = self.torch.cat([_flatten(self.hidden[0],batch_size),_flatten(self.hidden[1],batch_size)])\n",
    "        return x\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "class LSTMDecoder:\n",
    "    def __init__(self):\n",
    "        super(LSTMDecoder,self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            384,\n",
    "            50,\n",
    "            num_layers = 2,\n",
    "            bidirectional = True,\n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.hidden = (torch.zeros(2 * 2, 100000, 50).cuda(),\n",
    "                        torch.zeros(2 * 2, 100000, 50).cuda())\n",
    "    def forward(self,x):\n",
    "        batch_size = x.size(0)\n",
    "        _,self.hidden = self.lstm(x,self.hidden)\n",
    "        x = self.torch.cat([_flatten(self.hidden[0],batch_size),_flatten(self.hidden[1],batch_size)])\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class LSTMAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTMAutoEncoder, self).__init__()\n",
    "        self.encoder = LSTMEncoder()\n",
    "        self.decoder = LSTMDecoder()\n",
    "\n",
    "    def forward(self,x):\n",
    "        z = self.encoder(x)\n",
    "        return self.decoder(x,z)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.load(open('sentiment/vader.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eef27a2038de45a29bf3d758b589c29a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "reading in snapshots..:   0%|          | 0/221 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3abd2c548c404512a468756eaf504b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loading tokens...:   0%|          | 0/221 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa9a232882b416f842ef6afa5f0a9b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vader sentiment scores..:   0%|          | 0/22021502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-76e09a8815fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m'snapshots'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m'tokens/text'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;34m'vader'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;32m/data/blockchain-interoperability/blockchain-social-media/analysis/twitter/dataset.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(snapshot_path, token_path, sentiment_type)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mclean_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0msentiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentiment_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokens'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/blockchain-interoperability/blockchain-social-media/analysis/twitter/sentiment.py\u001b[0m in \u001b[0;36mget_sentiment\u001b[0;34m(sentiment_type, tokens)\u001b[0m\n\u001b[1;32m     38\u001b[0m ):\n\u001b[1;32m     39\u001b[0m     \u001b[0manalyzer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mANALYZERS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentiment_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mSENTIMENT_MAPPING\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentiment_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34mf'{sentiment_type} sentiment scores..'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mleave\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data/blockchain-interoperability/blockchain-social-media/analysis/twitter/sentiment.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     38\u001b[0m ):\n\u001b[1;32m     39\u001b[0m     \u001b[0manalyzer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mANALYZERS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentiment_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mSENTIMENT_MAPPING\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentiment_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34mf'{sentiment_type} sentiment scores..'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mleave\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data/blockchain-interoperability/blockchain-social-media/blockchain-sns-env/lib64/python3.6/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/blockchain-interoperability/blockchain-social-media/blockchain-sns-env/lib64/python3.6/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1196\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1197\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m                 \u001b[0;31m# Note: does not call self.update(1) for speed optimisation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from dataset import load_dataset\n",
    "\n",
    "dset = load_dataset(\n",
    "    'snapshots',\n",
    "    'tokens/text',\n",
    "    'vader'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 384, got 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-e14dfc66fe6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m384\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhhh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mebs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data/blockchain-interoperability/blockchain-social-media/blockchain-sns-env/lib64/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/blockchain-interoperability/blockchain-social-media/blockchain-sns-env/lib64/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "\u001b[0;32m/data/blockchain-interoperability/blockchain-social-media/blockchain-sns-env/lib64/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    630\u001b[0m                            \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                            ):\n\u001b[0;32m--> 632\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m         self.check_hidden_size(hidden[0], self.get_expected_hidden_size(input, batch_sizes),\n\u001b[1;32m    634\u001b[0m                                'Expected hidden[0] size {}, got {}')\n",
      "\u001b[0;32m/data/blockchain-interoperability/blockchain-social-media/blockchain-sns-env/lib64/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    205\u001b[0m             raise RuntimeError(\n\u001b[1;32m    206\u001b[0m                 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(\n\u001b[0;32m--> 207\u001b[0;31m                     self.input_size, input.size(-1)))\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 384, got 1"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "hh = (torch.zeros(2 * 2, 100000, 50).cuda(),\n",
    "torch.zeros(2 * 2, 100000, 50).cuda())\n",
    "\n",
    "\n",
    "ll = nn.LSTM(384,50,num_layers = 2,bidirectional=True).cuda()\n",
    "\n",
    "_,hhh = ll(ebs[:,:,None],hh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100000, 384, 1])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebs[:,:,None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LSTMEncoder().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input must have 3 dimensions, got 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-ef32aacee9ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mebs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data/blockchain-interoperability/blockchain-social-media/blockchain-sns-env/lib64/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-80-3652e374e3b4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/blockchain-interoperability/blockchain-social-media/blockchain-sns-env/lib64/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/blockchain-interoperability/blockchain-social-media/blockchain-sns-env/lib64/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "\u001b[0;32m/data/blockchain-interoperability/blockchain-social-media/blockchain-sns-env/lib64/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    630\u001b[0m                            \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                            ):\n\u001b[0;32m--> 632\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m         self.check_hidden_size(hidden[0], self.get_expected_hidden_size(input, batch_sizes),\n\u001b[1;32m    634\u001b[0m                                'Expected hidden[0] size {}, got {}')\n",
      "\u001b[0;32m/data/blockchain-interoperability/blockchain-social-media/blockchain-sns-env/lib64/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    201\u001b[0m             raise RuntimeError(\n\u001b[1;32m    202\u001b[0m                 'input must have {} dimensions, got {}'.format(\n\u001b[0;32m--> 203\u001b[0;31m                     expected_input_dim, input.dim()))\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             raise RuntimeError(\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input must have 3 dimensions, got 2"
     ]
    }
   ],
   "source": [
    "le(ebs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cenc = ConvAutoencoder()\n",
    "lenc = LinearAutoEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a805b4a530094a9b8cb5054e3c1b5cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.002409222535789013\n",
      "loss: 0.004125208128243685\n",
      "loss: 0.0023909281007945538\n",
      "loss: 0.002432329813018441\n",
      "loss: 0.002463673474267125\n",
      "loss: 0.0024721170775592327\n",
      "loss: 0.0024827364832162857\n",
      "loss: 0.0024854594375938177\n",
      "loss: 0.00248575652949512\n",
      "loss: 0.0024866077583283186\n",
      "loss: 0.002486886689439416\n",
      "loss: 0.0024863595608621836\n",
      "loss: 0.0024846415035426617\n",
      "loss: 0.002483841497451067\n",
      "loss: 0.002484808675944805\n",
      "loss: 0.002484197961166501\n",
      "loss: 0.0024825020227581263\n",
      "loss: 0.002481407020241022\n",
      "loss: 0.002481244271621108\n",
      "loss: 0.0024815055076032877\n",
      "loss: 0.002481007482856512\n",
      "loss: 0.0024796975776553154\n",
      "loss: 0.002478713868185878\n",
      "loss: 0.0024784798733890057\n",
      "loss: 0.0024782337713986635\n",
      "loss: 0.002477183472365141\n",
      "loss: 0.0024760758969932795\n",
      "loss: 0.002475673332810402\n",
      "loss: 0.0024754612240940332\n",
      "loss: 0.002474902430549264\n",
      "loss: 0.0024742414243519306\n",
      "loss: 0.0024734698235988617\n",
      "loss: 0.002472821855917573\n",
      "loss: 0.0024727489799261093\n",
      "loss: 0.0024716167245060205\n",
      "loss: 0.002471020445227623\n",
      "loss: 0.002470472827553749\n",
      "loss: 0.002470012754201889\n",
      "loss: 0.0024696404580026865\n",
      "loss: 0.002469132887199521\n",
      "loss: 0.002468761056661606\n",
      "loss: 0.0024684052914381027\n",
      "loss: 0.0024678038898855448\n",
      "loss: 0.0024671631399542093\n",
      "loss: 0.002466714708134532\n",
      "loss: 0.0024663074873387814\n",
      "loss: 0.0024658124893903732\n",
      "loss: 0.002465310972183943\n",
      "loss: 0.0024648611433804035\n",
      "loss: 0.00246432819403708\n",
      "loss: 0.0024637572932988405\n",
      "loss: 0.002463269978761673\n",
      "loss: 0.0024628022219985723\n",
      "loss: 0.002462257631123066\n",
      "loss: 0.0024617277085781097\n",
      "loss: 0.0024612434208393097\n",
      "loss: 0.002460752846673131\n",
      "loss: 0.0024603393394500017\n",
      "loss: 0.002459994750097394\n",
      "loss: 0.0024595463182777166\n",
      "loss: 0.0024590203538537025\n",
      "loss: 0.00245852954685688\n",
      "loss: 0.0024580666795372963\n",
      "loss: 0.002457601949572563\n",
      "loss: 0.0024572014808654785\n",
      "loss: 0.002456807531416416\n",
      "loss: 0.0024563733022660017\n",
      "loss: 0.0024559753946959972\n",
      "loss: 0.002455526264384389\n",
      "loss: 0.0024550564121454954\n",
      "loss: 0.0024546273052692413\n",
      "loss: 0.0024541805032640696\n",
      "loss: 0.002453769790008664\n",
      "loss: 0.0024533551186323166\n",
      "loss: 0.0024529460351914167\n",
      "loss: 0.0024525283370167017\n",
      "loss: 0.0024520112201571465\n",
      "loss: 0.0024517232086509466\n",
      "loss: 0.0024511879310011864\n",
      "loss: 0.002450884785503149\n",
      "loss: 0.0024504566099494696\n",
      "loss: 0.0024499755818396807\n",
      "loss: 0.0024494556710124016\n",
      "loss: 0.002448765328153968\n",
      "loss: 0.0024484312161803246\n",
      "loss: 0.0024480707943439484\n",
      "loss: 0.002447524107992649\n",
      "loss: 0.0024473080411553383\n",
      "loss: 0.0024469569325447083\n",
      "loss: 0.0024465343449264765\n",
      "loss: 0.002446037484332919\n",
      "loss: 0.00244556344114244\n",
      "loss: 0.0024450842756778\n",
      "loss: 0.002444571815431118\n",
      "loss: 0.0024443399161100388\n",
      "loss: 0.0024436975363641977\n",
      "loss: 0.002443452598527074\n",
      "loss: 0.002443156437948346\n",
      "loss: 0.002442784607410431\n",
      "loss: 0.0024423464201390743\n"
     ]
    }
   ],
   "source": [
    "lenc = lenc.cuda()\n",
    "ebs = ebs.cuda()\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from torch.optim import Adam\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = Adam(lenc.parameters())\n",
    "\n",
    "for epoch in tqdm(range(100)):\n",
    "    optimizer.zero_grad()\n",
    "    out = lenc(ebs)\n",
    "    loss = criterion(out,ebs)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print('loss:',loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.0142, -0.0514, -0.0092,  ..., -0.0590,  0.0263, -0.0186],\n",
       "          [-0.0144, -0.0498, -0.0098,  ..., -0.0611,  0.0287, -0.0238],\n",
       "          [-0.0161, -0.0476, -0.0110,  ..., -0.0630,  0.0261, -0.0264],\n",
       "          ...,\n",
       "          [-0.0186, -0.0546, -0.0111,  ..., -0.0615,  0.0250, -0.0196],\n",
       "          [-0.0160, -0.0532, -0.0101,  ..., -0.0651,  0.0306, -0.0196],\n",
       "          [-0.0153, -0.0519, -0.0112,  ..., -0.0588,  0.0262, -0.0187]]],\n",
       "        device='cuda:0', grad_fn=<CudnnRnnBackward0>),\n",
       " (tensor([[[ 0.0736, -0.0770,  0.0472,  ...,  0.0218,  0.0110,  0.0582],\n",
       "           [ 0.0399, -0.0315,  0.0418,  ...,  0.0015, -0.0241,  0.0735],\n",
       "           [ 0.0694, -0.0744,  0.0485,  ..., -0.0373, -0.0011,  0.0570],\n",
       "           ...,\n",
       "           [ 0.0538, -0.0286,  0.0435,  ...,  0.0115, -0.0127,  0.0633],\n",
       "           [ 0.0478, -0.0478,  0.0557,  ..., -0.0201, -0.0188,  0.0618],\n",
       "           [ 0.0744, -0.0674,  0.0315,  ...,  0.0036, -0.0265,  0.0644]],\n",
       "  \n",
       "          [[-0.0142, -0.0514, -0.0092,  ..., -0.0590,  0.0263, -0.0186],\n",
       "           [-0.0144, -0.0498, -0.0098,  ..., -0.0611,  0.0287, -0.0238],\n",
       "           [-0.0161, -0.0476, -0.0110,  ..., -0.0630,  0.0261, -0.0264],\n",
       "           ...,\n",
       "           [-0.0186, -0.0546, -0.0111,  ..., -0.0615,  0.0250, -0.0196],\n",
       "           [-0.0160, -0.0532, -0.0101,  ..., -0.0651,  0.0306, -0.0196],\n",
       "           [-0.0153, -0.0519, -0.0112,  ..., -0.0588,  0.0262, -0.0187]]],\n",
       "         device='cuda:0', grad_fn=<CudnnRnnBackward0>),\n",
       "  tensor([[[ 0.1545, -0.1643,  0.1039,  ...,  0.0478,  0.0214,  0.1183],\n",
       "           [ 0.0825, -0.0697,  0.0872,  ...,  0.0033, -0.0457,  0.1521],\n",
       "           [ 0.1403, -0.1559,  0.1032,  ..., -0.0828, -0.0022,  0.1176],\n",
       "           ...,\n",
       "           [ 0.1134, -0.0619,  0.0902,  ...,  0.0273, -0.0246,  0.1481],\n",
       "           [ 0.0975, -0.1024,  0.1129,  ..., -0.0469, -0.0382,  0.1324],\n",
       "           [ 0.1522, -0.1512,  0.0671,  ...,  0.0086, -0.0485,  0.1324]],\n",
       "  \n",
       "          [[-0.0297, -0.0962, -0.0199,  ..., -0.1242,  0.0548, -0.0410],\n",
       "           [-0.0301, -0.0934, -0.0213,  ..., -0.1267,  0.0602, -0.0524],\n",
       "           [-0.0338, -0.0897, -0.0237,  ..., -0.1325,  0.0550, -0.0591],\n",
       "           ...,\n",
       "           [-0.0395, -0.1029, -0.0241,  ..., -0.1288,  0.0527, -0.0431],\n",
       "           [-0.0333, -0.1007, -0.0218,  ..., -0.1367,  0.0648, -0.0435],\n",
       "           [-0.0323, -0.0984, -0.0245,  ..., -0.1227,  0.0550, -0.0412]]],\n",
       "         device='cuda:0', grad_fn=<CudnnRnnBackward0>)))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "isinstance() arg 2 must be a type or tuple of types",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-bac048b81993>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: isinstance() arg 2 must be a type or tuple of types"
     ]
    }
   ],
   "source": [
    "isinstance((1,1),(2,2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 ('blockchain-sns-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "6cd29d4fa90de0455862d632ba5d82eded8ec761054fa1c425c75462c69e58ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
