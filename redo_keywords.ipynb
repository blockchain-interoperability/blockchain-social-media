{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we are using cpu üêåüêåüêå\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ffc8016b354f2cad19f02cc8ecba8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cache in 116 seconds\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from crypto_chatter.config import load_default_data_config, load_default_graph_config\n",
    "from crypto_chatter.config.path import BASE_DIR\n",
    "from crypto_chatter.data import CryptoChatterData\n",
    "\n",
    "dataset = 'twitter:blockchain-interoperability-attacks'\n",
    "graph_type = 'tweet'\n",
    "data_config = load_default_data_config(dataset)\n",
    "graph_config = load_default_graph_config(dataset, graph_type)\n",
    "\n",
    "init_clusters = json.load(open(data_config.data_dir / 'kmeans_init_clusters.json'))\n",
    "\n",
    "old_kmeans_dir = BASE_DIR / 'old/analysis-data/kmeans_clusters_resampled'\n",
    "resample_clusters = {\n",
    "    i: json.load(open(old_kmeans_dir / f'{i}_ids.json'))\n",
    "    for i in range(6)\n",
    "}\n",
    "\n",
    "data = CryptoChatterData(data_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fit_tfidf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from crypto_chatter.data.utils import is_spam,preprocess_text\n",
    "\n",
    "random_size = 1000000\n",
    "text = data[data.data_config.text_col].values\n",
    "rng = np.random.RandomState(0)\n",
    "# first filter out spam\n",
    "not_spam = [t for t in text if not is_spam(t)]\n",
    "# Then get random indices\n",
    "random_idxs = rng.permutation(np.arange(len(not_spam)))[:random_size]\n",
    "subset = [preprocess_text(not_spam[i]) for i in random_idxs]\n",
    "\n",
    "top_n = 10\n",
    "terms = data.tfidf.get_feature_names_out()\n",
    "vecs = data.tfidf.transform(subset)\n",
    "tfidf_scores = vecs.toarray().sum(0)\n",
    "sorted_idxs = tfidf_scores.argsort()[::-1]\n",
    "keywords = terms[sorted_idxs][:top_n]\n",
    "keyword_scores = tfidf_scores[sorted_idxs][:top_n]\n",
    "keywords_with_score = dict(zip(keywords, keyword_scores))\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user' 'http' 'pump' 'just' 'signal' 'happen' 'crypto' 'wallstreetbets'\n",
      " 'event' 'kucoin']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of crypto_chatter.data.tfidf failed: Traceback (most recent call last):\n",
      "  File \"/Users/inwon/miniconda3/envs/twitter/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/inwon/miniconda3/envs/twitter/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/Users/inwon/miniconda3/envs/twitter/lib/python3.10/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 879, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1017, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 947, in source_to_code\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/Users/inwon/Documents/research/blockchain-social-media/crypto_chatter/data/tfidf.py\", line 53\n",
      "    )\n",
      "     ^\n",
      "SyntaxError: expected ':'\n",
      "]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "old_ids = pickle.load(open('/Users/inwon/Downloads/id.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0\n",
      "['user' 'pump' 'http' 'signal' 'just' 'event' 'happen' 'wallstreetbets'\n",
      " 'kucoin' 'big']\n",
      "V2\n",
      "['birdie' 'asinine' 'actors' 'bakht_md1' 'agulu' '80x5imzeqg'\n",
      " 'abvp68thconfjaipur' 'bkexglobal' 'aimkellar' '2437']\n",
      "================================================================================\n",
      "Cluster 1\n",
      "['user' 'crypto' 'http' 'promote' 'roll' 'token' 'price' '000' 'binance'\n",
      " 'security']\n",
      "V2\n",
      "['341800' '07477579' '12cq' '2100522' '2461' '3330' '206086' '000' '03267'\n",
      " '2724']\n",
      "================================================================================\n",
      "Cluster 2\n",
      "['user' 'http' 'crypto' 'v2' 'rollup' 'address' 'tokens' 'claiming'\n",
      " 'compatible' 'evm']\n",
      "V2\n",
      "['anticipated' '50mp' '22pm' 'antivaxers' 'admission'\n",
      " '0x3556c6c04be64e14e750e99dc56f69592b0a51de' 'amir84186215' '1999' '1x'\n",
      " '353take']\n",
      "================================================================================\n",
      "Cluster 3\n",
      "['roll' 'crypto' 'sushi' 'user' 'project' 'security' 'good' 'try' 'http'\n",
      " 'bridge']\n",
      "V2\n",
      "['059m' '00002170' '0924' '1208' '036100000' '0722' '00039049' '11245'\n",
      " '0008312' '000005370']\n",
      "================================================================================\n",
      "Cluster 4\n",
      "['user' 'http' 'pump' 'crypto' 'just' 'signal' 'kucoin' 'happen' 'event'\n",
      " 'wallstreetbets']\n",
      "V2\n",
      "['ax9qwwe5qk' '81' 'alpi' '360k' '9jncnpuv8q' 'apys' '_angelofcrypto_'\n",
      " '787457' '5129' 'babes']\n",
      "================================================================================\n",
      "Cluster 5\n",
      "['promote' 'user' 'crypto' 'price' 'roll' 'http' 'btc' 'binance' 'eth'\n",
      " 'bitcoin']\n",
      "V2\n",
      "['16317' '22478' '06973395005632536' '16200' '1706' '07921' '02698512'\n",
      " '01731' '07270000927640517' '01775']\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from crypto_chatter.data.utils import is_spam, preprocess_text\n",
    "\n",
    "stop_words = list(ENGLISH_STOP_WORDS | set(['https', '@']))\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "for cluster_id, cluster in init_clusters.items():\n",
    "    ids = [old_ids[i] for i in cluster]\n",
    "    text = [\n",
    "        preprocess_text(t)\n",
    "        for t in data[data.data_config.text_col][data.df['id'].isin(ids)].values\n",
    "        if not is_spam(t)\n",
    "    ]\n",
    "\n",
    "    sampled_text = ([\n",
    "        text[i]\n",
    "        for i in rng.permutation(len(text))[:100000]\n",
    "    ])\n",
    "    top_n = 10\n",
    "\n",
    "    terms = data.tfidf.get_feature_names_out()\n",
    "    vecs = data.tfidf.transform(sampled_text)\n",
    "    tfidf_scores = vecs.toarray().sum(0)\n",
    "    sorted_idxs = tfidf_scores.argsort()[::-1]\n",
    "    keywords = terms[sorted_idxs][:top_n]\n",
    "    keyword_scores = tfidf_scores[sorted_idxs][:top_n]\n",
    "    keywords_with_score = dict(zip(keywords, keyword_scores))\n",
    "    print('Cluster', cluster_id)\n",
    "    print(keywords)\n",
    "\n",
    "    tfidf = TfidfVectorizer(\n",
    "        stop_words=stop_words,\n",
    "        # ngram_range=ngram_range,\n",
    "        # max_df=max_df,\n",
    "        # min_df=min_df,\n",
    "        # max_features=max_features,\n",
    "    )\n",
    "\n",
    "    vecs = tfidf.fit_transform(sampled_text)\n",
    "    terms = tfidf.get_feature_names_out()\n",
    "    sorted_idxs = tfidf_scores.argsort()[::-1]\n",
    "    keywords = terms[sorted_idxs][:top_n]\n",
    "    keyword_scores = tfidf_scores[sorted_idxs][:top_n]\n",
    "    keywords_with_score = dict(zip(keywords, keyword_scores))\n",
    "    print('V2')\n",
    "    print(keywords)\n",
    "    \n",
    "    print('='*80)\n",
    "    # break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
