{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the autoencoder\n",
    "\n",
    "This file contains sample code for training the autoencoder used for dimensionali reduction in our stage 1 clustering (whole data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load embedding data -- huge!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from cache\n"
     ]
    }
   ],
   "source": [
    "from utils.embeddings import get_sbert_embeddings\n",
    "from pathlib import Path\n",
    "DATA_DIR = Path('/data/blockchain-interoperability/blockchain-social-media/twitter-data')\n",
    "\n",
    "embeddings = get_sbert_embeddings(\n",
    "    snapshot_path = DATA_DIR/'snapshots',\n",
    "    embeddings_path = DATA_DIR/'embeddings',\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn into torch dataloader\n",
    "\n",
    "This handles a bunch of things for you so you don't need to manually write code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# torch utility for shuffling/batching training data\n",
    "loader = DataLoader(embeddings,batch_size=1024, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the training loop.\n",
    "\n",
    "We want the loss to start settling at some value. Find the right epoch to train til."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a8f8579760f4ebdb3197b22039bb3d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14623 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss: 235.8681788375834\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d09490b067bb483c9ae3c04d907bb00d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14623 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss: 27.025784751749597\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fc60e55c9ff49dbbc54ec9d9b6c294c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14623 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss: 26.813517303555273\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96d98521b584f5d9fbb04e074255892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14623 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss: 26.740841245860793\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a0eaf20b8a64b7083d49758fc4d9270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14623 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss: 26.70676580327563\n"
     ]
    }
   ],
   "source": [
    "# train autoencoder\n",
    "import torch.nn.functional as F\n",
    "from utils.autoencoders import LinearAutoEncoder\n",
    "from torch.optim import SGD,Adam\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# we could use dataloader, but all the data is loaded already so no point..\n",
    "# batch_size = 1000\n",
    "\n",
    "autoenc = LinearAutoEncoder().cuda()\n",
    "# you can try different values for learing rate and weight_decay, and also try out Adam instaed of SGD\n",
    "\n",
    "# learning_rate: higher means more likely to overfit, faster weight updates\n",
    "# weight_decay: higher (closer to 1) means less weight decay. The same weights are preserved more. \n",
    "optimizer = SGD(autoenc.parameters(),lr=1e-2,momentum=0.9,weight_decay=1e-4)\n",
    "\n",
    "for epoch in range(5):\n",
    "    autoenc.train()\n",
    "    epoch_loss = 0\n",
    "    # iterate thru the dataloader\n",
    "    for batch in tqdm(loader):\n",
    "        autoenc.zero_grad()\n",
    "        batch = batch.cuda()\n",
    "        out = autoenc(batch)\n",
    "\n",
    "        loss = F.mse_loss(batch,out)\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'epoch_loss: {epoch_loss}')\n",
    "        \n",
    "\n",
    "        # break\n",
    "    # pass\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2564, device='cuda:0', grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# save the best model! ensure you write it under the data directory, so we don't include the huge file in git\n",
    "\n",
    "torch.save(autoenc.state_dict(), DATA_DIR/'best_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blockchain-sns-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "6cd29d4fa90de0455862d632ba5d82eded8ec761054fa1c425c75462c69e58ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
