{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the autoencoder\n",
    "\n",
    "This file contains sample code for training the autoencoder used for dimensionali reduction in our stage 1 clustering (whole data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load embedding data -- huge!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from cache\n"
     ]
    }
   ],
   "source": [
    "from utils.embeddings import get_sbert_embeddings\n",
    "from pathlib import Path\n",
    "DATA_DIR = Path('/data/blockchain-interoperability/blockchain-social-media/twitter-data')\n",
    "\n",
    "embeddings = get_sbert_embeddings(\n",
    "    snapshot_path = DATA_DIR/'snapshots',\n",
    "    embeddings_path = DATA_DIR/'embeddings',\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn into torch dataloader\n",
    "\n",
    "This handles a bunch of things for you so you don't need to manually write code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# torch utility for shuffling/batching training data\n",
    "loader = DataLoader(embeddings,batch_size=1024, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the training loop.\n",
    "\n",
    "We want the loss to start settling at some value. Find the right epoch to train til."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.autoencoders import LinearAutoEncoder\n",
    "from torch.optim import SGD\n",
    "\n",
    "autoenc = LinearAutoEncoder().cuda()\n",
    "# you can try different values for learing rate and weight_decay, and also try out Adam instaed of SGD\n",
    "\n",
    "# learning_rate: higher means more likely to overfit, faster weight updates\n",
    "# weight_decay: higher (closer to 1) means less weight decay. The same weights are preserved more. \n",
    "optimizer = SGD(autoenc.parameters(),lr=5e-2,momentum=0.9,weight_decay=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c2577e0478a4562aa2ad92c923895b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14623 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss: 73.21462510945275\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83ec38af2c484d738a1987281018f12f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14623 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss: 26.679077763459645\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8375e8d20c04421b929884949dc05ce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14623 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss: 26.645089064957574\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00a6f7d64b1f42a8be85d793a14a0083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14623 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss: 26.631291159195825\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e6feeb1bc0443d18fb79c292481ce48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14623 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss: 26.62438395351637\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf0d476e173142b29d5ee3b87cf526e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14623 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss: 26.62083490076475\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89f66deef1034c3886d6c61844c6b45c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14623 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss: 26.618962294305675\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "556fdb2bb09240f998f603433c0fe5bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14623 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss: 26.617966204532422\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4d46d45d26d4c97a9ce4b20925d5040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14623 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss: 26.61746647756081\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a29f1ee34143c7b8af9bf01a499a3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14623 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss: 26.617185704992153\n"
     ]
    }
   ],
   "source": [
    "# train autoencoder\n",
    "from utils.autoencoders import RMSELoss\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# we could use dataloader, but all the data is loaded already so no point..\n",
    "# batch_size = 1000\n",
    "\n",
    "\n",
    "for epoch in range(10):\n",
    "    autoenc.train()\n",
    "    epoch_loss = 0\n",
    "    # iterate thru the dataloader\n",
    "    for batch in tqdm(loader):\n",
    "        autoenc.zero_grad()\n",
    "        batch = batch.cuda()\n",
    "        out = autoenc(batch)\n",
    "\n",
    "        loss = F.mse_loss(batch,out)\n",
    "        # loss = RMSELoss(batch,out)\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'epoch_loss: {epoch_loss}')\n",
    "        \n",
    "\n",
    "        # break\n",
    "    # pass\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# save the best model! ensure you write it under the data directory, so we don't include the huge file in git\n",
    "\n",
    "torch.save(autoenc.state_dict(), DATA_DIR/'autoenc_10_epoch.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "something = [0,1,2,3,4]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blockchain-sns-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "6cd29d4fa90de0455862d632ba5d82eded8ec761054fa1c425c75462c69e58ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
