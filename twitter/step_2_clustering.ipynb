{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering the whole dataset\n",
    "\n",
    "In this step you should load the saved autoencoder and the embeddings, reduce the dimension of embeddings and apply some clustering (kmeans, hbdscan) to identify the clusters.\n",
    "Then you should save the cluster information (index of points in each cluster) to be used for analysis. \n",
    "\n",
    "The goal here is to identify broad topics that exist in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from cache\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from utils.autoencoders import LinearAutoEncoder\n",
    "\n",
    "# same deal\n",
    "from utils.embeddings import get_sbert_embeddings\n",
    "from pathlib import Path\n",
    "DATA_DIR = Path('/data/blockchain-interoperability/blockchain-social-media/twitter-data')\n",
    "\n",
    "embeddings = get_sbert_embeddings(\n",
    "    snapshot_path = DATA_DIR/'snapshots',\n",
    "    embeddings_path = DATA_DIR/'embeddings',\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# and the model\n",
    "autoenc = LinearAutoEncoder()\n",
    "autoenc.load_state_dict(torch.load(DATA_DIR/'autoenc_10_epoch.pkl'))\n",
    "# freeze the model, because we don't want to do any more calculations. This saves computational power\n",
    "autoenc.requires_grad = False\n",
    "# autoenc = autoenc.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of using the encoder\n",
    "# this line may not work, if it complains, just break into smaller batches and append them back. \n",
    "\n",
    "reduced_embs = autoenc.encoder(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14973497, 10])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_embs.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here the clustering starts..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the clusters are chosen, look inside the contents of each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# loads a pd.Series object that can be accessed by the indexes found in clusters\n",
    "whole_text = pd.read_pickle(DATA_DIR/'snapshots/whole_text.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blockchain-sns-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6cd29d4fa90de0455862d632ba5d82eded8ec761054fa1c425c75462c69e58ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
