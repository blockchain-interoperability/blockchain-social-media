{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "from pathlib import Path\n",
    "\n",
    "base_path = Path('/data/blockchain-interoperability/blockchain-social-media/twitter-data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall    & `crypto', `binance', `security', `pump', `token', `project', `signal', `kucoin', `happen', `event' \\\\ \\hline\n",
      "1    & `wallstreetbets', `big', `announced', `airdrop', `group', `massive', `hours', `whales', `blockchain', `really' \\\\ \\hline\n",
      "2    & `roll', `bridge', `price', `eth', `btc', `blockchain', `ftx', `like', `hack', `nft' \\\\ \\hline\n",
      "3    & `roll', `blockchain', `ftx', `bridge', `tokens', `nft', `like', `check', `learn', `address' \\\\ \\hline\n",
      "4    & `roll', `sushi', `bridge', `good', `hack', `try', `liquid', `btc', `bullish', `want' \\\\ \\hline\n",
      "5    & `blockchain', `wallstreetbets', `airdrop', `big', `group', `check', `nft', `roll', `join', `announced' \\\\ \\hline\n",
      "6    & `nftssaga', `promote', `roll', `price', `btc', `bridge', `eth', `bitcoin', `2022', `sushi' \\\\ \\hline\n"
     ]
    }
   ],
   "source": [
    "# cluster_id = 0\n",
    "to_remove = [\n",
    "    '开云体育',\n",
    "    '世界杯',\n",
    "    '上海',\n",
    "    '上海线下',\n",
    "    'gt',\n",
    "    'amp',\n",
    "]\n",
    "\n",
    "# def remove_keywords(list\n",
    "\n",
    "\n",
    "filter_type = 'cluster'\n",
    "\n",
    "keywords_file = base_path/f'sentiment_keywords/cluster_whole/{filter_type}_keywords.json'\n",
    "overall_keywords = json.load(open(keywords_file))\n",
    "\n",
    "print(f'Overall    & ' + ', '.join([f'`{t}\\'' for t in overall_keywords[:10]]) + ' \\\\\\\\ \\\\hline')\n",
    "for cluster_id in range(6):\n",
    "    # print(f'cluster {cluster_id}')\n",
    "    keywords_file = base_path/f'sentiment_keywords/cluster_{cluster_id}/{filter_type}_keywords.json'\n",
    "    keywords = json.load(open(keywords_file))\n",
    "\n",
    "    for t in to_remove:\n",
    "        if t in keywords: keywords.remove(t)\n",
    "\n",
    "    unique_top_10 = [k for k in keywords if k not in overall_keywords[:10]][:10]\n",
    "    # good_keywords = set(keywords) - to_remove\n",
    "    print(f'{cluster_id + 1}    & ' + ', '.join([f'`{t}\\'' for t in unique_top_10]) + ' \\\\\\\\ \\\\hline')\n",
    "    # print('--------------------')\n",
    "\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['event',\n",
       " 'happen',\n",
       " 'wallstreetbets',\n",
       " 'big',\n",
       " 'announced',\n",
       " 'airdrop',\n",
       " 'group',\n",
       " 'massive',\n",
       " 'hours',\n",
       " 'blockchain']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_keywords[]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blockchain-sns-env",
   "language": "python",
   "name": "blockchain-sns-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
